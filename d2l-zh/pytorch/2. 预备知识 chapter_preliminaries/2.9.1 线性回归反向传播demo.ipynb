{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd5b5b65-2da3-44c0-bc10-f1d91b5cd027",
   "metadata": {},
   "source": [
    "通过一个简单的线性回归模型来解释反向传播。线性回归模型的目标是找到一条线，使得所有数据点到这条线的距离（即误差）之和最小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c7ee60-0251-43ef-acb0-57613758e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前第0次训练的权重: tensor([1.2200], requires_grad=True)\n",
      "当前第1次训练的权重: tensor([1.3916], requires_grad=True)\n",
      "当前第2次训练的权重: tensor([1.5254], requires_grad=True)\n",
      "当前第3次训练的权重: tensor([1.6298], requires_grad=True)\n",
      "当前第4次训练的权重: tensor([1.7113], requires_grad=True)\n",
      "当前第5次训练的权重: tensor([1.7748], requires_grad=True)\n",
      "当前第6次训练的权重: tensor([1.8243], requires_grad=True)\n",
      "当前第7次训练的权重: tensor([1.8630], requires_grad=True)\n",
      "当前第8次训练的权重: tensor([1.8931], requires_grad=True)\n",
      "当前第9次训练的权重: tensor([1.9166], requires_grad=True)\n",
      "当前第10次训练的权重: tensor([1.9350], requires_grad=True)\n",
      "当前第11次训练的权重: tensor([1.9493], requires_grad=True)\n",
      "当前第12次训练的权重: tensor([1.9604], requires_grad=True)\n",
      "当前第13次训练的权重: tensor([1.9691], requires_grad=True)\n",
      "当前第14次训练的权重: tensor([1.9759], requires_grad=True)\n",
      "当前第15次训练的权重: tensor([1.9812], requires_grad=True)\n",
      "当前第16次训练的权重: tensor([1.9854], requires_grad=True)\n",
      "当前第17次训练的权重: tensor([1.9886], requires_grad=True)\n",
      "当前第18次训练的权重: tensor([1.9911], requires_grad=True)\n",
      "当前第19次训练的权重: tensor([1.9931], requires_grad=True)\n",
      "当前第20次训练的权重: tensor([1.9946], requires_grad=True)\n",
      "当前第21次训练的权重: tensor([1.9958], requires_grad=True)\n",
      "当前第22次训练的权重: tensor([1.9967], requires_grad=True)\n",
      "当前第23次训练的权重: tensor([1.9974], requires_grad=True)\n",
      "当前第24次训练的权重: tensor([1.9980], requires_grad=True)\n",
      "当前第25次训练的权重: tensor([1.9984], requires_grad=True)\n",
      "当前第26次训练的权重: tensor([1.9988], requires_grad=True)\n",
      "当前第27次训练的权重: tensor([1.9990], requires_grad=True)\n",
      "当前第28次训练的权重: tensor([1.9993], requires_grad=True)\n",
      "当前第29次训练的权重: tensor([1.9994], requires_grad=True)\n",
      "当前第30次训练的权重: tensor([1.9995], requires_grad=True)\n",
      "当前第31次训练的权重: tensor([1.9996], requires_grad=True)\n",
      "当前第32次训练的权重: tensor([1.9997], requires_grad=True)\n",
      "当前第33次训练的权重: tensor([1.9998], requires_grad=True)\n",
      "当前第34次训练的权重: tensor([1.9998], requires_grad=True)\n",
      "当前第35次训练的权重: tensor([1.9999], requires_grad=True)\n",
      "当前第36次训练的权重: tensor([1.9999], requires_grad=True)\n",
      "当前第37次训练的权重: tensor([1.9999], requires_grad=True)\n",
      "当前第38次训练的权重: tensor([1.9999], requires_grad=True)\n",
      "当前第39次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第40次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第41次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第42次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第43次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第44次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第45次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第46次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第47次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第48次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第49次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第50次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第51次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第52次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第53次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第54次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第55次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第56次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第57次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第58次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第59次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第60次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第61次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第62次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第63次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第64次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第65次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第66次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第67次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第68次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第69次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第70次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第71次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第72次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第73次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第74次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第75次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第76次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第77次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第78次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第79次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第80次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第81次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第82次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第83次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第84次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第85次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第86次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第87次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第88次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第89次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第90次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第91次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第92次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第93次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第94次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第95次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第96次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第97次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第98次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "当前第99次训练的权重: tensor([2.0000], requires_grad=True)\n",
      "训练后的权重: 1.999999761581421\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建数据\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])  # 输入数据\n",
    "y = torch.tensor([2.0, 4.0, 6.0, 8.0, 10.0])  # 实际结果\n",
    "\n",
    "# 初始化模型参数\n",
    "w = torch.tensor([1.0], requires_grad=True)  # 随机初始化权重\n",
    "\n",
    "# 学习率\n",
    "lr = 0.01\n",
    "\n",
    "# 训练模型\n",
    "for i in range(100):\n",
    "    # 前向传播：计算预测结果和损失\n",
    "    y_pred = w * x  # 使用当前的权重预测结果\n",
    "    loss = (y_pred - y).pow(2).mean()  # 计算预测结果和实际结果之间的差异（损失）\n",
    "\n",
    "    # 反向传播：计算损失对权重的梯度\n",
    "    loss.backward()  # PyTorch自动计算梯度\n",
    "\n",
    "    # 更新权重\n",
    "    with torch.no_grad():  # 在更新权重时，我们不需要计算梯度\n",
    "        w -= lr * w.grad  # 使用梯度下降更新权重\n",
    "        \n",
    "    print(f'当前第{i}次训练的权重: {w}')  # 输出当前循环更新的权重\n",
    "    \n",
    "    # 清零梯度\n",
    "    w.grad.zero_()\n",
    "\n",
    "print(f'训练后的权重: {w.item()}')  # 输出训练后的权重\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8015a8a4-2045-48b3-a86a-da43b5c0f9d3",
   "metadata": {},
   "source": [
    "首先创建了一些数据，然后初始化了模型的权重。\n",
    "然后，我们进行了100次训练迭代。\n",
    "在每次迭代中，我们首先进行前向传播，计算预测结果和损失，然后进行反向传播，计算损失对权重的梯度，最后我们使用这个梯度来更新权重。\n",
    "这个过程会一直重复，直到模型的性能达到满意的程度（在这个例子中，我们简单地进行了100次迭代）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
