{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d97442d",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 查阅文档\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a073d4",
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "由于篇幅限制，本书不可能介绍每一个PyTorch函数和类。\n",
    "API文档、其他教程和示例提供了本书之外的大量文档。\n",
    "本节提供了一些查看PyTorch API的指导。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b25fc6",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "## 查找模块中的所有函数和类\n",
    "\n",
    "为了知道模块中可以调用哪些函数和类，可以调用`dir`函数。\n",
    "例如，我们可以(**查询随机数生成模块中的所有属性：**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5639656b",
   "metadata": {
    "origin_pos": 6,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PositiveDefiniteTransform', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(dir(torch.distributions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c95a230",
   "metadata": {
    "origin_pos": 9
   },
   "source": [
    "通常可以忽略以“`__`”（双下划线）开始和结束的函数，它们是Python中的特殊对象，\n",
    "或以单个“`_`”（单下划线）开始的函数，它们通常是内部函数。\n",
    "根据剩余的函数名或属性名，我们可能会猜测这个模块提供了各种生成随机数的方法，\n",
    "包括从均匀分布（`uniform`）、正态分布（`normal`）和多项分布（`multinomial`）中采样。\n",
    "\n",
    "## 查找特定函数和类的用法\n",
    "\n",
    "有关如何使用给定函数或类的更具体说明，可以调用`help`函数。\n",
    "例如，我们来[**查看张量`ones`函数的用法。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701b67a7",
   "metadata": {
    "origin_pos": 11,
    "scrolled": true,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function normal in module torch:\n",
      "\n",
      "normal(...)\n",
      "    normal(mean, std, *, generator=None, out=None) -> Tensor\n",
      "    \n",
      "    Returns a tensor of random numbers drawn from separate normal distributions\n",
      "    whose mean and standard deviation are given.\n",
      "    \n",
      "    The :attr:`mean` is a tensor with the mean of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The :attr:`std` is a tensor with the standard deviation of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
      "    total number of elements in each tensor need to be the same.\n",
      "    \n",
      "    .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
      "              is used as the shape for the returned output tensor\n",
      "    \n",
      "    .. note:: When :attr:`std` is a CUDA tensor, this function synchronizes\n",
      "              its device with the CPU.\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "    \n",
      "    Keyword args:\n",
      "        generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
      "        tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
      "                  8.0505,   8.1408,   9.0563,  10.0566])\n",
      "    \n",
      "    .. function:: normal(mean=0.0, std, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the means are shared among all drawn\n",
      "    elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (float, optional): the mean for all distributions\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
      "        tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
      "    \n",
      "    .. function:: normal(mean, std=1.0, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the standard deviations are shared among\n",
      "    all drawn elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (float, optional): the standard deviation for all distributions\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 6.))\n",
      "        tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
      "    \n",
      "    .. function:: normal(mean, std, size, *, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Similar to the function above, but the means and standard deviations are shared\n",
      "    among all drawn elements. The resulting tensor has size given by :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        mean (float): the mean for all distributions\n",
      "        std (float): the standard deviation for all distributions\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(2, 3, size=(1, 4))\n",
      "        tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4283d",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "从文档中，我们可以看到`ones`函数创建一个具有指定形状的新张量，并将所有元素值设置为1。\n",
    "下面来[**运行一个快速测试**]来确认这一解释：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a66953e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:28:24.993229Z",
     "iopub.status.busy": "2022-12-07T16:28:24.992792Z",
     "iopub.status.idle": "2022-12-07T16:28:25.006286Z",
     "shell.execute_reply": "2022-12-07T16:28:25.005519Z"
    },
    "origin_pos": 16,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9056fb3d",
   "metadata": {
    "origin_pos": 19
   },
   "source": [
    "在Jupyter记事本中，我们可以使用`?`指令在另一个浏览器窗口中显示文档。\n",
    "例如，`list?`指令将创建与`help(list)`指令几乎相同的内容，并在新的浏览器窗口中显示它。\n",
    "此外，如果我们使用两个问号，如`list??`，将显示实现该函数的Python代码。\n",
    "\n",
    "## 小结\n",
    "\n",
    "* 官方文档提供了本书之外的大量描述和示例。\n",
    "* 可以通过调用`dir`和`help`函数或在Jupyter记事本中使用`?`和`??`查看API的用法文档。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 在深度学习框架中查找任何函数或类的文档。请尝试在这个框架的官方网站上找到文档。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3bed2c",
   "metadata": {
    "origin_pos": 21,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1765)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
